# Non-anthropocentric approaches to AI existential safety

I have been looking at issues related to technological singularity and AI existential safety since 1998.

This year I have returned to this topic because of the seismic shocks associated with the latest LLM revolution.

Looking back, it is clear that I was always focusing on **non-anthropocentric approaches**. This makes my research
sufficiently unusual, and so it makes sense to continue it and to keep good notes.



