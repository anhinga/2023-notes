
The [non-anthropocentric-short.md](non-anthropocentric-short.md) essay is posted on LessWrong on April 3, 2023: 

  * https://www.lesswrong.com/posts/WJuASYDnhZ8hs5CnD/exploring-non-anthropocentric-aspects-of-ai-existential
  
  * https://www.greaterwrong.com/posts/WJuASYDnhZ8hs5CnD/exploring-non-anthropocentric-aspects-of-ai-existential

The first part, the non-anthropocentric existential safety associated with drastic progress in physics goes back to my 1998 essay.

That part gives rise to the following actionable items of research:

  * Interpretability, self-interpretability by AI, and mutual interpretability by AIs
  * Cooperation versus competition in multi-agent systems
  * Ability to competently perform moral reasoning
  * Studying the technical problems of rapidly self-improving systems including stability and invariance of some important goals, values, and constraints

But the situation also does depend a lot on how the world actually works (which is something we don't know,
and something better thinkers will likely discover; what's safe and what's not safe will crucially depend on that).
